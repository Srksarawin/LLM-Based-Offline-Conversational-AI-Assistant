### LLM Based Offline Conversational AI Assistant

Objective:
The Core idea of this project is to provide an AI assistant that can work in offline, as most of the AI Assistants are network dependent, my project is to make an AI Assistant that works on offline.

Tech Stacks:
For this: 
I have used LLaMa-3.2 (1B) LLM for reasoning purpose and explain the features and also to solve the queries of the user.
For Speech conversion, I used Faster-whisper (small) model, so that we can achieve high accuracy with low specs and also to reduce latency in the applications.

I provide the link for downloading the LLMS:

[LLaMA](https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/blob/main/Llama-3.2-1B-Instruct-Q4_K_L.gguf)
[Faster-whisper](https://huggingface.co/Systran/faster-whisper-small/tree/main)

In faster-whisper download all the files and put it in separate folder.

THE PROJECT STRUCTURE

![image](image.png)
  
  
